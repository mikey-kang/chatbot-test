#!/usr/bin/env python
# coding: utf-8

import streamlit as st

def main():

	# Title
	st.title("ìˆ˜ì•„ Version 1.0.0")
	st.subheader("")
	st.markdown("""
		AI ì±—ë´‡ ìˆ˜ì•„ì˜ 1.0.0 Versionì…ë‹ˆë‹¤ğŸ‘©ğŸ»â€âš•ï¸
		"""
		"""
		ìˆ˜ì•„ì™€ ëŒ€í™”ë¥¼ í•˜ë©°, ìœ„ë¡œì™€ ê³µê°ì„ ë°›ì•„ë³´ì„¸ìš”ğŸ˜Š
	""")

	st.subheader("ì±—ë´‡ê³¼ ëŒ€í™”í•´ë³´ì„¸ìš”!")

	utterance = st.text_input("ë‚˜: ", "ì˜¤ëŠ˜ì€ ì–´ë–¤ ê¸°ë¶„ì´ì‹ ê°€ìš”?")

	st.sidebar.subheader("Generation Settings")
	maxlen=st.sidebar.slider("max length of the sequence", 30, 60,value=50)
	numbeams=st.sidebar.slider("number of beams", 5,20, value=10)
	topk=st.sidebar.slider("top k sampling", 10, 50, value=20)
	ngramsize=st.sidebar.slider("Ngram size not to repeat", 1,4,value=2)
	temp=st.sidebar.slider("temperature: threshold probability of each token", 0.7, 0.95, value=0.85)
	sampling=st.sidebar.checkbox("do sampling", value=False)


	st.sidebar.subheader("(ì£¼)ì•„ëª¬ë””")
	st.sidebar.text("Copyright 2023. amondy Inc. All rights reserved.")

	if st.button("ì „ì†¡"):
# 		result = chat(utterance,maxlen,numbeams,sampling,topk,ngramsize,temp)
# 		st.text_area("ì±—ë´‡: ", value=result)
		st.text_area("ì±—ë´‡: ", value="ì„±ê³µ")

	st.sidebar.subheader("ê°œë°œì")
	st.sidebar.text("ê¹€ì€ì§„, jyej3154@snu.ac.kr")
	st.sidebar.text("ì„œìš¸ëŒ€í•™êµ ì–¸ì–´í•™ê³¼ ì„ì‚¬ê³¼ì •")

	st.subheader("ì°¸ì¡°")
	st.markdown("kogpt2 ê¸°ë°˜ ì±—ë´‡: https://github.com/haven-jeon/KoGPT2-chatbot")
	st.markdown("pytorch lightning: https://www.pytorchlightning.ai/")
	st.markdown("huggingface transformers: https://huggingface.co/")
	st.markdown("wellness dataset: https://aihub.or.kr/keti_data_board/language_intelligence")

if __name__ == '__main__':
	main()
